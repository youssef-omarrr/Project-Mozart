{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248ca238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import REMI\n",
    "\n",
    "# Choose a tokenizer\n",
    "tokenizer = REMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4f62fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing MIDI files: 100%|██████████| 182/182 [00:13<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 284\n",
      "First 10 tokens: [('PAD_None', 0), ('BOS_None', 1), ('EOS_None', 2), ('MASK_None', 3), ('Bar_None', 4), ('Pitch_21', 5), ('Pitch_22', 6), ('Pitch_23', 7), ('Pitch_24', 8), ('Pitch_25', 9)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|██████████| 182/182 [00:08<00:00, 21.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from create_data import get_vocab_size, create_dataset_and_dataloader\n",
    "\n",
    "vocab_size, sequences = get_vocab_size(tokenizer, test_print=True)\n",
    "dataset, train_loader, val_loader = create_dataset_and_dataloader(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2b90d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded best model (no epoch/val_loss info saved)\n"
     ]
    }
   ],
   "source": [
    "from create_model import MusicTransformer\n",
    "import torch\n",
    "\n",
    "ckpt_path = \"checkpoints/best_model.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "vocab_size = 284\n",
    "model = MusicTransformer(vocab_size)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "print(\"✅ Loaded best model (no epoch/val_loss info saved)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e428950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 12223/12223 [04:27<00:00, 45.74it/s, main_loss=1.8939, struct_loss=1.4022, lr=1.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished | Train main: 1.8939 | Train struct: 1.4022 | Val: 1.1413\n",
      "New best model saved with validation loss: 1.1413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 12223/12223 [04:14<00:00, 47.99it/s, main_loss=1.1839, struct_loss=1.3711, lr=1.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished | Train main: 1.1839 | Train struct: 1.3711 | Val: 1.1323\n",
      "New best model saved with validation loss: 1.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 12223/12223 [04:42<00:00, 43.22it/s, main_loss=1.1728, struct_loss=1.3661, lr=1.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished | Train main: 1.1728 | Train struct: 1.3661 | Val: 1.1284\n",
      "New best model saved with validation loss: 1.1284\n",
      "Training completed! Best validation loss: 1.1284\n"
     ]
    }
   ],
   "source": [
    "from train_model import train\n",
    "\n",
    "train(model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        tokenizer,\n",
    "        epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a073324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering 'model_outputs/midi_files\\generated_2.mid' to WAV...\n",
      "Using SoundFont: ../soundfonts/AegeanSymphonicOrchestra-SND.sf2\n",
      "Output path: model_outputs/midi_files\\generated_2.wav\n",
      "✅ Successfully converted MIDI to WAV: model_outputs/midi_files\\generated_2.wav\n",
      "✅ Saved: model_outputs/midi_files\\generated_2.mid and model_outputs/midi_files\\generated_2.wav\n"
     ]
    }
   ],
   "source": [
    "from generate import generate\n",
    "\n",
    "_ = generate(model, tokenizer, max_len= 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697460a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
