{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562743d8",
   "metadata": {},
   "source": [
    "| `one_token_stream_for_programs` | Best For                          | Pros                                                | Cons                                |\n",
    "| ------- | --------------------------------- | --------------------------------------------------- | ----------------------------------- |\n",
    "| `True`  | Simpler training, small datasets  | Unified sequence, learns inter-instrument relations | More token noise, program switching |\n",
    "| `False` | Multi-instrument/orchestral music | Clean per-instrument modeling                       | Requires multi-stream handling      |\n",
    "\n",
    "> \\\n",
    "> In this notebook we will try both by chaning the `one_token_stream_test` bool variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d354d3c7",
   "metadata": {},
   "source": [
    "## To Fix generated tokens\n",
    "\n",
    "###  `tokenizer.complete_sequence()`\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "When you generate or edit token sequences manually (e.g., from a model output), some tokens may be incomplete or inconsistent, missing tempo, bar, or program context, etc.\n",
    "`complete_sequence()` fills in or fixes those missing pieces so that the sequence can be decoded safely into a valid MIDI file.\n",
    "\n",
    "```python\n",
    "tokens = model.generate(...)\n",
    "tokens = tokenizer.complete_sequence(tokens)\n",
    "midi = tokenizer.decode(tokens)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e3fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Codess & Projects\\.venv\\lib\\site-packages\\miditok\\tokenizations\\remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "564 tokens with ('T',) io format (one token stream), not trained"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "one_token_stream_test = True\n",
    "\n",
    "# Set up a config that gives you REMI+ behavior\n",
    "config = TokenizerConfig(                   \n",
    "    use_programs=True,                         # Include instrument program numbers (to distinguish instruments)\n",
    "    one_token_stream_for_programs              # (if true) Merge all instruments into a single token stream instead of separating them\n",
    "    = one_token_stream_test,   \n",
    "    program_changes = True,     \n",
    "    use_time_signatures = True,                  # Include time signature tokens in the encoding\n",
    "    use_chords=True,                           # (Optional) Detect and include chord tokens\n",
    "    use_rests=True,                            # (Optional) Represent silence periods as rest tokens\n",
    "    use_tempos=True,                           # (Optional) Include tempo change tokens\n",
    ")\n",
    "\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f490a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_midi_file = \"../../midi_tests/3-Due_pupille.mid\"\n",
    "\n",
    "token = tokenizer(test_midi_file)\n",
    "# token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5312980a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(ttype=Tick, tpq=16, begin=0, end=1504, tracks=4, notes=601, time_sig=1, key_sig=0, markers=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.decode(token)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5c7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.dump_midi(\"one_token_stream_True.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0934c267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2371"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b84041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(ttype=Tick, tpq=16, begin=0, end=1504, tracks=4, notes=601, time_sig=1, key_sig=0, markers=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids = tokenizer.decode(token.ids)\n",
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36205423",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids.dump_midi(\"ids_test.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e93d75a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f9389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564 tokens with ('I', 'T') io format, not trained"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "one_token_stream_test = False\n",
    "\n",
    "# Set up a config that gives you REMI+ behavior\n",
    "config = TokenizerConfig(                   \n",
    "    use_programs=True,                         # Include instrument program numbers (to distinguish instruments)\n",
    "    one_token_stream_for_programs              # (if true) Merge all instruments into a single token stream instead of separating them\n",
    "    = one_token_stream_test,        \n",
    "    use_time_signatures=True,                  # Include time signature tokens in the encoding\n",
    "    use_chords=True,                           # (Optional) Detect and include chord tokens\n",
    "    use_rests=True,                            # (Optional) Represent silence periods as rest tokens\n",
    "    use_tempos=True                            # (Optional) Include tempo change tokens\n",
    ")\n",
    "\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_midi_file = \"../../midi_tests/3-Due_pupille.mid\"\n",
    "\n",
    "token = tokenizer(test_midi_file)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd31ba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(ttype=Tick, tpq=16, begin=0, end=1504, tracks=5, notes=601, time_sig=1, key_sig=0, markers=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.decode(token)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f927eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.dump_midi(\"one_token_stream_False.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296ba0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Codess & Projects\\.venv\\lib\\site-packages\\miditok\\tokenizations\\remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "564 tokens with ('T',) io format (one token stream), not trained"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "config = TokenizerConfig(\n",
    "    # ----- Instruments -----\n",
    "    use_programs=True,                         # Distinguish instruments via program numbers\n",
    "    one_token_stream_for_programs=True,       # Merge instruments into one stream (if False â†’ one stream per program)\n",
    "    program_changes=True,                       # Add ProgramChange tokens\n",
    "\n",
    "    # ----- Musical structure -----\n",
    "    use_time_signatures=True,                   # Add TimeSignature tokens\n",
    "    use_tempos=True,                            # Add Tempo tokens\n",
    "    use_chords=True,                            # Detect and include chord tokens\n",
    "    use_rests=True,                             # Represent silences as Rest tokens\n",
    "\n",
    "    # ----- Velocity and duration -----\n",
    "    include_velocity=True,                      # Include velocity tokens (for dynamics)\n",
    "    )\n",
    "\n",
    "tokenizer = REMI(config)\n",
    "tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76580a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_midi_file = \"../../midi_tests/3-Due_pupille.mid\"\n",
    "\n",
    "token = tokenizer.encode(test_midi_file)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4e54c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(ttype=Tick, tpq=16, begin=0, end=1504, tracks=4, notes=601, time_sig=1, key_sig=0, markers=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.decode(token)\n",
    "output\n",
    "# Score(ttype=Tick, tpq=16, begin=0, end=1504, tracks=4, notes=601, time_sig=1, key_sig=0, markers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46399086",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.dump_midi(\"one_token_stream_True_2.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f046102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Codess & Projects\\.venv\\lib\\site-packages\\miditok\\tokenizations\\remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n",
      "Tokenizing MIDI files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182/182 [00:33<00:00,  5.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from music_tokenizer import get_tokenized_data\n",
    "\n",
    "get_tokenized_data(\"../../dataset/midi_dataset\", \"../../dataset/tokens_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing MIDI files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182/182 [00:31<00:00,  5.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from music_tokenizer import get_tokenizer\n",
    "\n",
    "def get_tokenized_data(midi_path:str):\n",
    "    \n",
    "    # 1. get tokenizer\n",
    "    tokenizer = get_tokenizer()\n",
    "    \n",
    "    # 2. change midi_path string to Path objects\n",
    "    midi_path = Path(midi_path)\n",
    "    tokenized = []\n",
    "    \n",
    "    # 3. loop through every midi file in the midi_path\n",
    "    for midi in tqdm(list(midi_path.glob(\"*.mid\")), desc=\"Tokenizing MIDI files\"):\n",
    "        # 3.1. tokenize midi file\n",
    "        tokens = tokenizer(midi)\n",
    "        # 3.2. append the ids only to the tokenized list\n",
    "        tokenized.append(tokens.ids)    \n",
    "        \n",
    "    return tokenized\n",
    "            \n",
    "tokenized = get_tokenized_data(\"../../dataset/midi_dataset\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f851a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
